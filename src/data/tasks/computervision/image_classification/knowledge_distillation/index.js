export const KnowledgeDistillation = {
    title: 'Knowledge Distillation',
    img: "https://production-media.paperswithcode.com/thumbnails/task/task-0000000951-52325f45_O0tAMly.jpg",
    description: "Knowledge distillation is the process of transferring knowledge from a large model to a smaller one. While large models (such as very deep neural networks or ensembles of many models) have higher knowledge capacity than small models, this capacity might not be fully utilized.",
    datasets: ["ImageNet"],
    models: [
        
    ]
}

export default KnowledgeDistillation;